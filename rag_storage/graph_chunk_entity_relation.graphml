<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d13" for="edge" attr.name="truncate" attr.type="string"/>
<key id="d12" for="edge" attr.name="created_at" attr.type="long"/>
<key id="d11" for="edge" attr.name="file_path" attr.type="string"/>
<key id="d10" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d9" for="edge" attr.name="keywords" attr.type="string"/>
<key id="d8" for="edge" attr.name="description" attr.type="string"/>
<key id="d7" for="edge" attr.name="weight" attr.type="double"/>
<key id="d6" for="node" attr.name="truncate" attr.type="string"/>
<key id="d5" for="node" attr.name="created_at" attr.type="long"/>
<key id="d4" for="node" attr.name="file_path" attr.type="string"/>
<key id="d3" for="node" attr.name="source_id" attr.type="string"/>
<key id="d2" for="node" attr.name="description" attr.type="string"/>
<key id="d1" for="node" attr.name="entity_type" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_id" attr.type="string"/>
<graph edgedefault="undirected"><node id="Kafka">
  <data key="d0">Kafka</data>
  <data key="d1">concept</data>
  <data key="d2">A distributed streaming platform that retains events for a configured period, partitions topics, and provides various APIs.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Events">
  <data key="d0">Events</data>
  <data key="d1">data</data>
  <data key="d2">Units of data published to Kafka topics, which are retained for a configurable duration instead of being deleted after consumption.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Topics">
  <data key="d0">Topics</data>
  <data key="d1">concept</data>
  <data key="d2">Logical channels in Kafka to which events are published and from which consumers read; they are partitioned and can be replicated.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Consumers">
  <data key="d0">Consumers</data>
  <data key="d1">concept</data>
  <data key="d2">Entities that subscribe to and read streams of events from Kafka topics, always reading partition events in the order they were written.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Traditional Messaging Systems">
  <data key="d0">Traditional Messaging Systems</data>
  <data key="d1">concept</data>
  <data key="d2">Systems where events are typically deleted immediately after consumption, unlike Kafka.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Kafka Brokers">
  <data key="d0">Kafka Brokers</data>
  <data key="d1">artifact</data>
  <data key="d2">Servers in a Kafka cluster where topic partitions are physically located, enabling distributed data storage.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Client Applications">
  <data key="d0">Client Applications</data>
  <data key="d1">concept</data>
  <data key="d2">Software that interacts with Kafka, reading and writing data from/to Kafka brokers simultaneously for scalability.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Event Key">
  <data key="d0">Event Key</data>
  <data key="d1">concept</data>
  <data key="d2">An event key is a conceptual component of an event.&lt;SEP&gt;An identifier (e.g., customer or vehicle ID) used to ensure that events with the same key are written to the same topic partition.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e&lt;SEP&gt;chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Partitions">
  <data key="d0">Partitions</data>
  <data key="d1">concept</data>
  <data key="d2">Divisions of a Kafka topic, spread across multiple Kafka brokers, enabling parallel processing and scalability.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Producers">
  <data key="d0">Producers</data>
  <data key="d1">concept</data>
  <data key="d2">Client applications that publish or write new events to Kafka topics and their partitions.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Geo-Regions">
  <data key="d0">Geo-Regions</data>
  <data key="d1">location</data>
  <data key="d2">Geographical areas across which Kafka topics can be replicated to ensure data fault-tolerance and high availability.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Datacenters">
  <data key="d0">Datacenters</data>
  <data key="d1">location</data>
  <data key="d2">Facilities across which Kafka topics can be replicated to provide fault tolerance and high availability for data.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Replication Factor">
  <data key="d0">Replication Factor</data>
  <data key="d1">data</data>
  <data key="d2">A configuration setting, commonly set to 3, that defines how many copies of topic-partition data are maintained for fault tolerance.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Admin API (Kafka)">
  <data key="d0">Admin API (Kafka)</data>
  <data key="d1">method</data>
  <data key="d2">One of Kafka's five core APIs, used for managing and inspecting topics, brokers, and other Kafka objects.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Producer API (Kafka)">
  <data key="d0">Producer API (Kafka)</data>
  <data key="d1">method</data>
  <data key="d2">One of Kafka's five core APIs, used to publish (write) a stream of events to one or more Kafka topics.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Consumer API (Kafka)">
  <data key="d0">Consumer API (Kafka)</data>
  <data key="d1">method</data>
  <data key="d2">One of Kafka's five core APIs, used to subscribe to (read) one or more topics and process the event stream.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Kafka Streams API">
  <data key="d0">Kafka Streams API</data>
  <data key="d1">method</data>
  <data key="d2">One of Kafka's five core APIs, designed to implement stream processing applications and microservices with higher-level functions.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Kafka Connect API">
  <data key="d0">Kafka Connect API</data>
  <data key="d1">method</data>
  <data key="d2">One of Kafka's five core APIs, used to build and run reusable data import/export connectors for integration with external systems.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Java (Language)">
  <data key="d0">Java (Language)</data>
  <data key="d1">concept</data>
  <data key="d2">A programming language for which Kafka provides core APIs.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Scala (Language)">
  <data key="d0">Scala (Language)</data>
  <data key="d1">concept</data>
  <data key="d2">A programming language for which Kafka provides core APIs.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Kafka Documentation">
  <data key="d0">Kafka Documentation</data>
  <data key="d1">content</data>
  <data key="d2">Comprehensive information explaining Kafka's concepts in full detail.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Kafka Quickstart">
  <data key="d0">Kafka Quickstart</data>
  <data key="d1">content</data>
  <data key="d2">A guide offering hands-on experience to get started with Kafka.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Kafka Books">
  <data key="d0">Kafka Books</data>
  <data key="d1">content</data>
  <data key="d2">Published resources available for understanding Kafka in more detail.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Academic Papers (Kafka)">
  <data key="d0">Academic Papers (Kafka)</data>
  <data key="d1">content</data>
  <data key="d2">Scholarly articles providing in-depth understanding of Kafka.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743576</data>
  <data key="d6"></data>
</node>
<node id="Kafka Use Cases">
  <data key="d0">Kafka Use Cases</data>
  <data key="d1">content</data>
  <data key="d2">Examples demonstrating how users globally are deriving value from Kafka.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Local Kafka Meetup Group">
  <data key="d0">Local Kafka Meetup Group</data>
  <data key="d1">organization</data>
  <data key="d2">A community group for Kafka users to join and watch talks.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Kafka Summit">
  <data key="d0">Kafka Summit</data>
  <data key="d1">event</data>
  <data key="d2">The main conference of the Kafka community, featuring talks.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Kafka Community">
  <data key="d0">Kafka Community</data>
  <data key="d1">organization</data>
  <data key="d2">The Kafka community provides dozens of clients that augment those included with Kafka.&lt;SEP&gt;A worldwide network of users and contributors around Kafka.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e&lt;SEP&gt;chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="PostgreSQL">
  <data key="d0">PostgreSQL</data>
  <data key="d1">organization</data>
  <data key="d2">A relational database mentioned as an example of an external system that can integrate with Kafka via connectors.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Stream Processing Applications">
  <data key="d0">Stream Processing Applications</data>
  <data key="d1">concept</data>
  <data key="d2">Applications and microservices that can be implemented using the Kafka Streams API to process event streams.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Data Import/Export Connectors">
  <data key="d0">Data Import/Export Connectors</data>
  <data key="d1">artifact</data>
  <data key="d2">Reusable tools built using the Kafka Connect API to consume or produce streams of events from and to external systems.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="External Systems">
  <data key="d0">External Systems</data>
  <data key="d1">concept</data>
  <data key="d2">Other applications and systems that can integrate with Kafka using connectors to consume or produce event streams.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Topic Configuration Setting">
  <data key="d0">Topic Configuration Setting</data>
  <data key="d1">concept</data>
  <data key="d2">A per-topic configuration setting in Kafka that defines for how long Kafka should retain events.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Data Size">
  <data key="d0">Data Size</data>
  <data key="d1">concept</data>
  <data key="d2">A characteristic of data that Kafka's performance remains constant with respect to.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Scalability">
  <data key="d0">Scalability</data>
  <data key="d1">concept</data>
  <data key="d2">The ability of Kafka to handle increased workloads, achieved by distributing topics over partitions and allowing client applications to read and write from many brokers simultaneously.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Network (Computing)">
  <data key="d0">Network (Computing)</data>
  <data key="d1">concept</data>
  <data key="d2">The infrastructure over which producer clients publish new events to Kafka topic partitions.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Fault Tolerance">
  <data key="d0">Fault Tolerance</data>
  <data key="d1">concept</data>
  <data key="d2">A design principle ensuring that Kafka data remains available even if some components fail, achieved through topic replication.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="High Availability">
  <data key="d0">High Availability</data>
  <data key="d1">concept</data>
  <data key="d2">A design principle ensuring continuous operation of Kafka data, supported by topic replication across multiple brokers, geo-regions, or datacenters.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Replication">
  <data key="d0">Replication</data>
  <data key="d1">concept</data>
  <data key="d2">The process of creating and maintaining multiple copies of Kafka topic-partition data to ensure fault-tolerance and high availability.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Microservices">
  <data key="d0">Microservices</data>
  <data key="d1">concept</data>
  <data key="d2">Small, independent services that can be implemented using the Kafka Streams API to process event streams.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Relational Database">
  <data key="d0">Relational Database</data>
  <data key="d1">concept</data>
  <data key="d2">Relational databases are existing systems that Kafka Connect can integrate with for continuous data import and export.&lt;SEP&gt;A type of database, such as PostgreSQL, that can integrate with Kafka via data import/export connectors.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e&lt;SEP&gt;chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Command Line Tooling (Kafka)">
  <data key="d0">Command Line Tooling (Kafka)</data>
  <data key="d1">artifact</data>
  <data key="d2">Tools provided by Kafka for management and administration tasks.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Kafka APIs (Collection)">
  <data key="d0">Kafka APIs (Collection)</data>
  <data key="d1">concept</data>
  <data key="d2">A set of five core APIs provided by Kafka for Java and Scala, including Admin, Producer, Consumer, Streams, and Connect APIs.</data>
  <data key="d3">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Apache Kafka">
  <data key="d0">Apache Kafka</data>
  <data key="d1">artifact</data>
  <data key="d2">Apache Kafka is an event streaming platform described as a distributed system consisting of servers and clients that communicate via a high-performance TCP network protocol, offering capabilities to publish, subscribe, store, and process streams of events.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Event Streaming">
  <data key="d0">Event Streaming</data>
  <data key="d1">concept</data>
  <data key="d2">Event streaming is the practice of capturing, storing, manipulating, processing, reacting to, and routing data in real-time as streams of events, serving as a technological foundation for automated software-defined businesses.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Event">
  <data key="d0">Event</data>
  <data key="d1">data</data>
  <data key="d2">An event records the fact that "something happened" and is the fundamental unit of data in Kafka, conceptually having a key, value, timestamp, and optional metadata headers.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Producer">
  <data key="d0">Producer</data>
  <data key="d1">method</data>
  <data key="d2">Producers are client applications that publish or write events to Kafka, fully decoupled from consumers to achieve high scalability.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Consumer">
  <data key="d0">Consumer</data>
  <data key="d1">method</data>
  <data key="d2">Consumers are client applications that subscribe to, read, and process events from Kafka, operating independently from producers.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Topic">
  <data key="d0">Topic</data>
  <data key="d1">concept</data>
  <data key="d2">A topic is a mechanism in Kafka for organizing and durably storing events, similar to a folder in a filesystem, supporting multiple producers and subscribers and retaining events for a configurable duration.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Kafka Cluster">
  <data key="d0">Kafka Cluster</data>
  <data key="d1">system</data>
  <data key="d2">A Kafka cluster is a distributed system comprising one or more servers that can span multiple datacenters or cloud regions, providing high scalability and fault tolerance for mission-critical use cases.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Broker">
  <data key="d0">Broker</data>
  <data key="d1">artifact</data>
  <data key="d2">Brokers are servers within a Kafka cluster that form the storage layer, responsible for storing event streams.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Kafka Connect">
  <data key="d0">Kafka Connect</data>
  <data key="d1">artifact</data>
  <data key="d2">Kafka Connect is a component run on Kafka servers to continuously import and export data as event streams, integrating Kafka with existing systems like relational databases and other Kafka clusters.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Client">
  <data key="d0">Client</data>
  <data key="d1">artifact</data>
  <data key="d2">Clients are applications that allow users to write distributed applications and microservices to read, write, and process streams of events in parallel, at scale, and in a fault-tolerant manner.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="TCP Network Protocol">
  <data key="d0">TCP Network Protocol</data>
  <data key="d1">method</data>
  <data key="d2">The TCP network protocol is a high-performance protocol used by Kafka servers and clients for communication.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Datacenter">
  <data key="d0">Datacenter</data>
  <data key="d1">location</data>
  <data key="d2">Datacenters are physical locations where Kafka clusters can be deployed, potentially spanning multiple regions.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Cloud Region">
  <data key="d0">Cloud Region</data>
  <data key="d1">location</data>
  <data key="d2">Cloud regions are geographical areas in cloud environments where Kafka clusters can be deployed.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Kafka Streams Library">
  <data key="d0">Kafka Streams Library</data>
  <data key="d1">content</data>
  <data key="d2">The Kafka Streams library is a higher-level client included with Kafka, available for Java and Scala, used for processing streams of events.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743577</data>
  <data key="d6"></data>
</node>
<node id="Event-Driven Architecture">
  <data key="d0">Event-Driven Architecture</data>
  <data key="d1">concept</data>
  <data key="d2">Event-driven architecture is a software design pattern for which event streaming can serve as a foundation.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Microservice">
  <data key="d0">Microservice</data>
  <data key="d1">concept</data>
  <data key="d2">Microservices are a software development approach that can be built using Kafka clients and event streaming as a foundation.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Data Platform">
  <data key="d0">Data Platform</data>
  <data key="d1">concept</data>
  <data key="d2">A data platform is a system for managing and processing data, for which event streaming can serve as a foundation.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Event Source">
  <data key="d0">Event Source</data>
  <data key="d1">concept</data>
  <data key="d2">Event sources are origins from which data is captured in real-time in the form of streams of events, such as databases, sensors, mobile devices, cloud services, and software applications.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Bare-Metal Hardware">
  <data key="d0">Bare-Metal Hardware</data>
  <data key="d1">artifact</data>
  <data key="d2">Bare-metal hardware is a deployment environment on which Kafka can be deployed.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Virtual Machine">
  <data key="d0">Virtual Machine</data>
  <data key="d1">artifact</data>
  <data key="d2">Virtual machines are a deployment environment on which Kafka can be deployed.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Container">
  <data key="d0">Container</data>
  <data key="d1">artifact</data>
  <data key="d2">Containers are a deployment environment on which Kafka can be deployed.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Event Value">
  <data key="d0">Event Value</data>
  <data key="d1">data</data>
  <data key="d2">An event value is a conceptual component of an event.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Event Timestamp">
  <data key="d0">Event Timestamp</data>
  <data key="d1">data</data>
  <data key="d2">An event timestamp is a conceptual component of an event.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Metadata Header">
  <data key="d0">Metadata Header</data>
  <data key="d1">data</data>
  <data key="d2">Metadata headers are optional conceptual components of an event.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Partition">
  <data key="d0">Partition</data>
  <data key="d1">concept</data>
  <data key="d2">A partition is a division of a topic, spreading it over a number of servers.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="Programming Language">
  <data key="d0">Programming Language</data>
  <data key="d1">concept</data>
  <data key="d2">Programming languages are the environments for which Kafka clients are available.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<node id="REST API">
  <data key="d0">REST API</data>
  <data key="d1">method</data>
  <data key="d2">REST APIs are a method through which Kafka clients are available.</data>
  <data key="d3">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d4">unknown_source</data>
  <data key="d5">1766743578</data>
  <data key="d6"></data>
</node>
<edge source="Kafka" target="Events">
  <data key="d7">1.0</data>
  <data key="d8">Kafka is a platform designed to retain and process streams of events.</data>
  <data key="d9">data retention,stream processing</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743578</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Topics">
  <data key="d7">1.0</data>
  <data key="d8">Kafka organizes events into topics for publishing and consumption.</data>
  <data key="d9">data flow,organization</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Admin API (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">Kafka includes an Admin API for managing and inspecting Kafka objects.</data>
  <data key="d9">functionality,management</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Producer API (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">Kafka includes a Producer API for publishing streams of events.</data>
  <data key="d9">functionality,publishing</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Consumer API (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">Kafka includes a Consumer API for subscribing to and processing event streams.</data>
  <data key="d9">functionality,subscription</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Kafka Streams API">
  <data key="d7">1.0</data>
  <data key="d8">Kafka includes the Kafka Streams API for implementing stream processing applications.</data>
  <data key="d9">functionality,stream processing</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Kafka Connect API">
  <data key="d7">1.0</data>
  <data key="d8">Kafka includes the Kafka Connect API for building data import/export connectors.</data>
  <data key="d9">functionality,integration</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Java (Language)">
  <data key="d7">1.0</data>
  <data key="d8">Kafka provides core APIs for Java.</data>
  <data key="d9">api support,programming</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Scala (Language)">
  <data key="d7">1.0</data>
  <data key="d8">Kafka provides core APIs for Scala.</data>
  <data key="d9">api support,programming</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Kafka Quickstart">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Quickstart provides hands-on experience with Kafka.</data>
  <data key="d9">experience,learning</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Kafka Documentation">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Documentation explains Kafka's various concepts in full detail.</data>
  <data key="d9">information,learning</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Kafka Books">
  <data key="d7">1.0</data>
  <data key="d8">Kafka books offer a way to understand Kafka in more detail.</data>
  <data key="d9">information,learning</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Academic Papers (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">Academic papers offer a way to understand Kafka in more detail.</data>
  <data key="d9">information,learning</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Kafka Use Cases">
  <data key="d7">1.0</data>
  <data key="d8">Kafka use cases demonstrate how users are getting value out of Kafka.</data>
  <data key="d9">demonstration,value proposition</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Topic Configuration Setting">
  <data key="d7">1.0</data>
  <data key="d8">Kafka retains events based on a per-topic configuration setting.</data>
  <data key="d9">configuration,data retention</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Data Size">
  <data key="d7">1.0</data>
  <data key="d8">Kafka's performance is constant with respect to data size, allowing for long-term data storage.</data>
  <data key="d9">performance,scaling</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Command Line Tooling (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">Kafka provides command line tooling for management and administration tasks.</data>
  <data key="d9">management,tooling</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka" target="Kafka APIs (Collection)">
  <data key="d7">1.0</data>
  <data key="d8">Kafka has five core APIs, which form the Kafka APIs collection.</data>
  <data key="d9">contains,functionality</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Events" target="Topics">
  <data key="d7">1.0</data>
  <data key="d8">Events are published to and retained within topics.</data>
  <data key="d9">containment,data flow</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Events" target="Partitions">
  <data key="d7">1.0</data>
  <data key="d8">When a new event is published to a topic, it is appended to one of the topicâ€™s partitions.</data>
  <data key="d9">append,storage</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Events" target="Producer API (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">The Producer API is used to publish (write) a stream of events.</data>
  <data key="d9">publishing,writing</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Events" target="Consumer API (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">The Consumer API is used to process streams of events.</data>
  <data key="d9">processing,reading</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Events" target="Kafka Streams API">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Streams API provides higher-level functions to process event streams.</data>
  <data key="d9">processing,transformation</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Consumers">
  <data key="d7">1.0</data>
  <data key="d8">Consumers subscribe to topics to read streams of events.</data>
  <data key="d9">data access,subscription</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743578</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Producers">
  <data key="d7">1.0</data>
  <data key="d8">Producers publish new events to topics.</data>
  <data key="d9">data flow,publishing</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743578</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Partitions">
  <data key="d7">1.0</data>
  <data key="d8">Topics are partitioned, meaning they are spread over a number of partitions.</data>
  <data key="d9">composition,distribution</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Replication Factor">
  <data key="d7">1.0</data>
  <data key="d8">The replication factor defines how many copies of a topic's data are maintained for fault tolerance.</data>
  <data key="d9">configuration,fault tolerance</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Geo-Regions">
  <data key="d7">1.0</data>
  <data key="d8">Topics can be replicated across geo-regions for fault-tolerance and high-availability.</data>
  <data key="d9">high availability,replication</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Datacenters">
  <data key="d7">1.0</data>
  <data key="d8">Topics can be replicated across datacenters for fault-tolerance and high-availability.</data>
  <data key="d9">high availability,replication</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Admin API (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">The Admin API is used to manage and inspect topics.</data>
  <data key="d9">inspection,management</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Fault Tolerance">
  <data key="d7">1.0</data>
  <data key="d8">Topics can be replicated to make data fault-tolerant.</data>
  <data key="d9">data protection,enablement</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="High Availability">
  <data key="d7">1.0</data>
  <data key="d8">Topics can be replicated to make data highly-available.</data>
  <data key="d9">data access,enablement</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Topics" target="Replication">
  <data key="d7">1.0</data>
  <data key="d8">Topics can undergo replication to create multiple copies of data.</data>
  <data key="d9">data copies,process</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Consumers" target="Partitions">
  <data key="d7">1.0</data>
  <data key="d8">Consumers of a given topic-partition will always read that partition's events in exactly the same order as they were written.</data>
  <data key="d9">ordered access,reading</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Brokers" target="Partitions">
  <data key="d7">1.0</data>
  <data key="d8">Partitions are located on different Kafka brokers.</data>
  <data key="d9">hosting,location</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Brokers" target="Client Applications">
  <data key="d7">1.0</data>
  <data key="d8">Client applications read and write data from/to Kafka brokers.</data>
  <data key="d9">data access,interaction</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Brokers" target="Admin API (Kafka)">
  <data key="d7">1.0</data>
  <data key="d8">The Admin API is used to manage and inspect brokers.</data>
  <data key="d9">inspection,management</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Event Key" target="Partitions">
  <data key="d7">1.0</data>
  <data key="d8">Events with the same event key are written to the same partition, ensuring ordered processing.</data>
  <data key="d9">ordering,routing</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743579</data>
  <data key="d13"></data>
</edge>
<edge source="Event Key" target="Event">
  <data key="d7">1.0</data>
  <data key="d8">An event conceptually has an event key.</data>
  <data key="d9">has component</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Partitions" target="Scalability">
  <data key="d7">1.0</data>
  <data key="d8">Partitions are important for scalability, allowing client applications to read and write data from many brokers.</data>
  <data key="d9">distribution,enabler</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Producers" target="Network (Computing)">
  <data key="d7">1.0</data>
  <data key="d8">Producers publish new events to topics by writing events over the network.</data>
  <data key="d9">data transfer,publishing</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Admin API (Kafka)" target="Kafka APIs (Collection)">
  <data key="d7">1.0</data>
  <data key="d8">The Admin API is one of Kafka's core APIs.</data>
  <data key="d9">composition,membership</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Producer API (Kafka)" target="Kafka APIs (Collection)">
  <data key="d7">1.0</data>
  <data key="d8">The Producer API is one of Kafka's core APIs.</data>
  <data key="d9">composition,membership</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Consumer API (Kafka)" target="Kafka APIs (Collection)">
  <data key="d7">1.0</data>
  <data key="d8">The Consumer API is one of Kafka's core APIs.</data>
  <data key="d9">composition,membership</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Streams API" target="Stream Processing Applications">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Streams API is used to implement stream processing applications and microservices.</data>
  <data key="d9">development,implementation</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Streams API" target="Microservices">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Streams API is used to implement microservices.</data>
  <data key="d9">development,implementation</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Streams API" target="Kafka APIs (Collection)">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Streams API is one of Kafka's core APIs.</data>
  <data key="d9">composition,membership</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Connect API" target="Data Import/Export Connectors">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Connect API is used to build and run reusable data import/export connectors.</data>
  <data key="d9">creation,functionality</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Connect API" target="Kafka APIs (Collection)">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Connect API is one of Kafka's core APIs.</data>
  <data key="d9">composition,membership</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Local Kafka Meetup Group" target="Kafka Community">
  <data key="d7">1.0</data>
  <data key="d8">Local Kafka Meetup Groups are part of the Kafka community.</data>
  <data key="d9">affiliation,networking</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Summit" target="Kafka Community">
  <data key="d7">1.0</data>
  <data key="d8">Kafka Summit is the main conference of the Kafka community.</data>
  <data key="d9">conference,event</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743581</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Community" target="Client">
  <data key="d7">1.0</data>
  <data key="d8">Dozens of clients for Kafka are provided by the Kafka community.</data>
  <data key="d9">provided by</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="PostgreSQL" target="Data Import/Export Connectors">
  <data key="d7">1.0</data>
  <data key="d8">A connector to a relational database like PostgreSQL can capture changes to tables.</data>
  <data key="d9">example,integration</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="Data Import/Export Connectors" target="External Systems">
  <data key="d7">1.0</data>
  <data key="d8">Data import/export connectors consume or produce event streams from and to external systems and applications.</data>
  <data key="d9">data transfer,integration</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743580</data>
  <data key="d13"></data>
</edge>
<edge source="External Systems" target="Relational Database">
  <data key="d7">1.0</data>
  <data key="d8">A relational database is an example of an external system that integrates with Kafka.</data>
  <data key="d9">categorization,example</data>
  <data key="d10">chunk-a15c8d50abd30a81a1bb191da6acd84e</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743582</data>
  <data key="d13"></data>
</edge>
<edge source="Relational Database" target="Kafka Connect">
  <data key="d7">1.0</data>
  <data key="d8">Kafka Connect integrates Kafka with existing systems like relational databases.</data>
  <data key="d9">imports from/exports to,integrates with</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Event Streaming">
  <data key="d7">1.0</data>
  <data key="d8">Apache Kafka is an event streaming platform that provides capabilities for event streaming.</data>
  <data key="d9">enables,platform</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Producer">
  <data key="d7">1.0</data>
  <data key="d8">Producers are client applications that publish events to Apache Kafka.</data>
  <data key="d9">publishes,writes to</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Consumer">
  <data key="d7">1.0</data>
  <data key="d8">Consumers are client applications that subscribe to events from Apache Kafka.</data>
  <data key="d9">reads from,subscribes to</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Kafka Cluster">
  <data key="d7">1.0</data>
  <data key="d8">Apache Kafka is run as a Kafka cluster of one or more servers.</data>
  <data key="d9">architecture,implemented as</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Client">
  <data key="d7">1.0</data>
  <data key="d8">Apache Kafka functions with clients for reading, writing, and processing events.</data>
  <data key="d9">interacts via,uses</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Bare-Metal Hardware">
  <data key="d7">1.0</data>
  <data key="d8">Apache Kafka can be deployed on bare-metal hardware.</data>
  <data key="d9">deployed on</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Virtual Machine">
  <data key="d7">1.0</data>
  <data key="d8">Apache Kafka can be deployed on virtual machines.</data>
  <data key="d9">deployed on</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Apache Kafka" target="Container">
  <data key="d7">1.0</data>
  <data key="d8">Apache Kafka can be deployed on containers.</data>
  <data key="d9">deployed on</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743585</data>
  <data key="d13"></data>
</edge>
<edge source="Event Streaming" target="Event">
  <data key="d7">1.0</data>
  <data key="d8">Event streaming is the practice of capturing, storing, processing, and routing events.</data>
  <data key="d9">composed of,constituent part</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Event Streaming" target="Event-Driven Architecture">
  <data key="d7">1.0</data>
  <data key="d8">Event streaming serves as the foundation for event-driven architectures.</data>
  <data key="d9">foundation for,supports</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Event Streaming" target="Microservice">
  <data key="d7">1.0</data>
  <data key="d8">Event streaming serves as the foundation for microservices.</data>
  <data key="d9">foundation for,supports</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Event Streaming" target="Data Platform">
  <data key="d7">1.0</data>
  <data key="d8">Event streaming serves as the foundation for data platforms.</data>
  <data key="d9">foundation for,supports</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Event Streaming" target="Event Source">
  <data key="d7">1.0</data>
  <data key="d8">Event streaming involves capturing data in real-time from event sources.</data>
  <data key="d9">captures data from</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Event" target="Topic">
  <data key="d7">1.0</data>
  <data key="d8">Events are organized and durably stored in topics within Kafka.</data>
  <data key="d9">organized in,stored in</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Event" target="Event Value">
  <data key="d7">1.0</data>
  <data key="d8">An event conceptually has an event value.</data>
  <data key="d9">has component</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Event" target="Event Timestamp">
  <data key="d7">1.0</data>
  <data key="d8">An event conceptually has an event timestamp.</data>
  <data key="d9">has component</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743585</data>
  <data key="d13"></data>
</edge>
<edge source="Event" target="Metadata Header">
  <data key="d7">1.0</data>
  <data key="d8">An event conceptually has optional metadata headers.</data>
  <data key="d9">has component,optional</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743585</data>
  <data key="d13"></data>
</edge>
<edge source="Topic" target="Partition">
  <data key="d7">1.0</data>
  <data key="d8">Topics in Kafka are partitioned, meaning they are spread over a number of partitions.</data>
  <data key="d9">comprises,divided into</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Cluster" target="Broker">
  <data key="d7">1.0</data>
  <data key="d8">Some servers in a Kafka cluster form the storage layer called brokers.</data>
  <data key="d9">component,contains</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Cluster" target="Kafka Connect">
  <data key="d7">1.0</data>
  <data key="d8">Other servers in a Kafka cluster run Kafka Connect.</data>
  <data key="d9">component,runs</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Cluster" target="Datacenter">
  <data key="d7">1.0</data>
  <data key="d8">A Kafka cluster can span multiple datacenters.</data>
  <data key="d9">deployed in,location</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Kafka Cluster" target="Cloud Region">
  <data key="d7">1.0</data>
  <data key="d8">A Kafka cluster can span multiple cloud regions.</data>
  <data key="d9">deployed in,location</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Client" target="TCP Network Protocol">
  <data key="d7">1.0</data>
  <data key="d8">Kafka clients communicate with servers via a high-performance TCP network protocol.</data>
  <data key="d9">communicates via,uses</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743583</data>
  <data key="d13"></data>
</edge>
<edge source="Client" target="Kafka Streams Library">
  <data key="d7">1.0</data>
  <data key="d8">The Kafka Streams library is a higher-level client for Kafka.</data>
  <data key="d9">included as,type of</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Client" target="Programming Language">
  <data key="d7">1.0</data>
  <data key="d8">Clients for Kafka are available for various programming languages.</data>
  <data key="d9">available in</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743584</data>
  <data key="d13"></data>
</edge>
<edge source="Client" target="REST API">
  <data key="d7">1.0</data>
  <data key="d8">Clients for Kafka are available via REST APIs.</data>
  <data key="d9">available via</data>
  <data key="d10">chunk-c7a6477706b973e2e63ad547b7ea2015</data>
  <data key="d11">unknown_source</data>
  <data key="d12">1766743585</data>
  <data key="d13"></data>
</edge>
</graph></graphml>